# Тестовое задание

## Логика сбора данных
### Твиттер
В твиттере пока оставил только твитты с упоминанием селебы. То есть, твитты типа: "Илон маск одныжды сказал" или "Илон маск сказал", после строки через split() поделены на 2 части и взята только 2 часть (Потому что пока, что не сделал нахождение шаблонов через NLP)

### Ютуб
На ютубе можно получить достатчно много хороших данных без "шумов", которые есть в твтиттере. Если брать подкасты/интервью, то там разговот 2-3 людей, что дает много данных по диалогам и вопрос-> ответ, а так как у них более высокий приоритет, то основной упор был сделан в платформу.


## Формат данных
Пока не придумал ничего лучше, чем хранить в json'e типа
```json
[
  {
  "phrases":
  [
    "phrase_0",
    "phrase_1",

  ]
  },
  {
  "video_0":
    {
    "questions":
      [
        "question_0",
        "question_1"

      ]
    },
    {
    "answers":
      [
        "answer_0",
        "answer_1",

      ]
    }
  },
  {
  "video_1":
    {
    "questions":
      [
        "question_0",
        "question_1"

      ]
    },
    {
    "answers":
      [
        "answer_0",
        "answer_1",

      ]
    }
  },

]
```
## Качество данных
### Фразы
Данные с очень большими погрешностями, потому что в твитах очень много вариаций "цитирования" и для отсеивания мусроной инфы надо написать шаблонизватор (пока не успел)

### Вопрос-> ответ/диалоги
Здесь качетсво данных обусловленно качеством субтитров, а также насколько они попадают в ответы селебы или вопросы журналиста.
Потому что сначала берется json полученный через youtube-transcript-api, хранящий субтитры и тайминги по типу:
```json
[
  {
    "text":"<text>",
    "start":"<start_time>",
    "duration":"<duration_time>"
  }
]
```
Далее все идёт по алгоритму:
- Полный подкаст/интервью пилится на кусики длинной duration_time и начиная с start_time (К сожалению у обученной модели подгрузка аудиофайлов идет только через путь к файлу, поэтому пришлось костылить и сохранять отрывки в файлы типа "extract_i.mp3", а потом уже с ним работать).
- Подгружается sample голоса Илона Маска и отрывок полного подкаста/интервью
- Проверяется кто говорит на отрывке:1) Илон Маск, 2)Журналист
- Если на отрывке говорит Илон Маск, то в answers добавляется текст с субтитров из отрывка
- Если говрит не Илон Маск, то текст добавляется в вопросы.
- В конце возвращается json, по типу:
```json
{
  "video_0":
    {
    "questions":
      [
        "question_0",
        "question_1"
      ]
    },
    {
    "answers":
      [
        "answer_0",
        "answer_1",
      ]
    }
  }
```

## Воспроизведение данных
Для того, чтобы получить json с фразами и диалогами/QnA 
нужно запустить 
```bash
python3 main.py
```
Данный скрипт вызовет
```python
search_tweets(<celeb_name>,<words>)
```
words - ключевые слова по которым надо искать твиты (на данный момент их 2:"once said","said")
данный метод вернетs str, где будут находиться части твитов после слова said. Эти части твитов можно рассматривать, как фразы (но пока что они очень сырые)

Также в скрипте в цикле вызовется 
```python
get_subtitles(video, i)
```
где video - это i-тая ссылка на ютуб виедо в списке videos,а i - индекс самого видео

Эта часть скрипта скачивает видео по ссылке в формате mp3 в папку audios,скачивает обученную модель нейронной сети, после режет скачанный mp3 файл на отрывки и проверяет сходятся ли голос на отрывке и голос в sample, при помощи метода класса SpeakerRecognition из [репозитория](https://github.com/speechbrain/speechbrain)
```python
verification.verify_files(<path_to_1_file>,<path_to_2_file>)
```
данный метод возвращает 2 torch тензора
```
tensor(score)
tensor(predition)
```
score - это уверенность в предсказании

prediction - похожи ли голоса в файлах  (True или False)

Также он удаляется посторонние звуки из субтитров по типу:
```python
audience_noices = ["[Laughter]", "[Music]", "[Applause]", "(Laughter)"]
```
